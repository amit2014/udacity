{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OpenStreetMap Data Wrangling with MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "To choose any area of the world in https://www.openstreetmap.org and use data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for that part of the world. Finally, use MongoDB as the data schema to complete your project by storing, querying and aggregating the data.\n",
    "\n",
    "### OSM Dataset\n",
    "The data area selected for this project is of the \"old\" Toronto area. This area was choosen primiarly because I currently live in the city of Toronto but specifically within the \"old\" Toronto area and not the \"new\" or \"Greater Toronto Area\" aka the GTA.\n",
    "\n",
    "Data was directly exported from OpenStreetMap (link provided below)\n",
    "- https://www.openstreetmap.org/relation/2989349#map=12/43.6789/-79.3851"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues\n",
    "After initially review/investigation of a sample set of the data I noticed three main problems. Each data problem will be discussed below.\n",
    "\n",
    "- abbreviated street names (St. as Street)\n",
    "- Duplicated abbreviation for different words (St. for Street vs St. for Saint)\n",
    "- Multiple abbreviations (Queen St E instead of Queen Street East)\n",
    "- Incorrect and inconsistent postal codes (format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Street names**\n",
    "\n",
    "Talk about how you cleaned things up - data/audit.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Postal codes**\n",
    "\n",
    "Talk about how you cleaned things up - data/audit.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Overview\n",
    "- Old_Toronto.osm: 176MB\n",
    "- Old_Toronto.osm.json: xMB\n",
    "- Total records: x\n",
    "\n",
    "**TODO:** updated for full dataset\n",
    "\n",
    "\n",
    "**Identifying tags and total counts**\n",
    "\n",
    "- \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "- \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "- \"problemchars\", for tags with problematic characters, and\n",
    "- \"other\", for other tags that do not fall into the other three categories.\n",
    "\n",
    "> {'lower': 5112, 'lower_colon': 3483, 'other': 96, 'problemchars': 0}\n",
    "- member: 277\n",
    "- nd: 7330\n",
    "- node: 6575\n",
    "- osm: 1\n",
    "- relation: 13\n",
    "- tag: 8691\n",
    "- way: 1239\n",
    "\n",
    "**Number of documents**\n",
    "                                                \n",
    "> db.char.find().count():\n",
    "                                                \n",
    "**Number of nodes**\n",
    "                                                \n",
    "> db.char.find({\"type\":\"node\"}).count()\n",
    "                                                \n",
    "**Number of ways**\n",
    "                                                \n",
    "> db.char.find({\"type\":\"way\"}).count()\n",
    "                                                \n",
    "**Number of unique users**\n",
    "                                                \n",
    "> db.char.distinct({\"created.user\"}).length\n",
    "                                                \n",
    "**Top 1 contributing user**\n",
    "                                                \n",
    "> db.char.aggregate...\n",
    "\n",
    "**Number of users appearing only once (having 1 post)**\n",
    "                                                \n",
    "> db.char.aggregate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 277,\n",
      " 'nd': 7330,\n",
      " 'node': 6575,\n",
      " 'osm': 1,\n",
      " 'relation': 13,\n",
      " 'tag': 8691,\n",
      " 'way': 1239}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for _, elem in ET.iterparse(filename):\n",
    "        tag = elem.tag\n",
    "        if tag not in tags.keys():\n",
    "            tags[tag] = 1\n",
    "        else:\n",
    "            tags[tag] += 1\n",
    "    return tags\n",
    "\n",
    "\n",
    "def test():\n",
    "    tags = count_tags('src/sample.osm')\n",
    "    pprint.pprint(tags)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying unique users**\n",
    "\n",
    "Number of unique contributors: 183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique contributors: 183\n"
     ]
    }
   ],
   "source": [
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        try:\n",
    "            users.add(element.attrib['uid'])\n",
    "        except KeyError:\n",
    "            # Some elements don't have a uid attribute, do nothing\n",
    "            continue\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "    users = process_map('src/sample.osm')\n",
    "    print 'Number of unique contributors:', len(users)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validating data tag 'k' attribute**\n",
    "\n",
    "{'lower': 5112, 'lower_colon': 3483, 'other': 96, 'problemchars': 0}\n",
    "\n",
    "- \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "- \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "- \"problemchars\", for tags with problematic characters, and\n",
    "- \"other\", for other tags that do not fall into the other three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 5112, 'lower_colon': 3483, 'other': 96, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        # search returns matchObject which is always true or None when 'false'\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "def test():\n",
    "    keys = process_map('src/sample.osm')\n",
    "    pprint.pprint(keys)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Additional ideas\n",
    "stuff\n",
    "### Final thoughts\n",
    "stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree\n",
    "- https://docs.python.org/2/library/re.html\n",
    "- http://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "- https://www.openstreetmap.org/relation/2989349#map=12/43.6789/-79.3851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
